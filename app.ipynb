{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b343e048",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f779daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-30 07:33:23.787289: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 07:33:23.836205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-30 07:33:23.836257: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-30 07:33:23.837700: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-30 07:33:23.844411: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-30 07:33:23.845326: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-30 07:33:24.968681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import io\n",
    "from PIL import Image, ImageDraw\n",
    "from flask import Flask, request, render_template, send_file, jsonify\n",
    "from werkzeug.utils import secure_filename\n",
    "import base64\n",
    "import tensorflow as tf\n",
    "from utils.model_utils import load_image_into_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b801d5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets\tfingerprint.pb\tsaved_model.pb\tvariables\r\n"
     ]
    }
   ],
   "source": [
    "!ls models/ssd_model/saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a380ded",
   "metadata": {},
   "source": [
    "## Defining Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f4af099",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/ssd_model/saved_model\"  \n",
    "UPLOAD_FOLDER = \"uploads\"\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349bc833",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0717d9fe",
   "metadata": {},
   "source": [
    "## Function to validate uploaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64b483f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316659c",
   "metadata": {},
   "source": [
    "## Loading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5c47b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90091836",
   "metadata": {},
   "source": [
    "## Functions to handle routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0102f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d5297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route for handling the prediction\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    detection_threshold = 0.5   \n",
    "    labels = ['Bicycle', 'cat', 'dog', 'Female', 'Male']\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['image']\n",
    "        if file and allowed_file(file.filename):\n",
    "            filename = secure_filename(file.filename)\n",
    "            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "            file.save(file_path)\n",
    "            \n",
    "            original_image = Image.open(file_path)\n",
    "            original_width, original_height = original_image.size\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            image_np = load_image_into_numpy_array(file_path, target_size=(224, 224))\n",
    "\n",
    "            # Prepare the image for the model\n",
    "            input_tensor = tf.convert_to_tensor([image_np], dtype=tf.uint8)\n",
    "\n",
    "            # Run the model using the appropriate signature\n",
    "            detections = model.signatures['serving_default'](input_tensor)\n",
    "\n",
    "            # Extract detection data\n",
    "            detection_boxes = detections['detection_boxes'].numpy()[0]\n",
    "            detection_classes = detections['detection_classes'].numpy()[0].astype(np.int64)\n",
    "            detection_scores = detections['detection_scores'].numpy()[0]\n",
    "\n",
    "            # Draw bounding boxes and labels on the image\n",
    "            image_with_boxes = Image.fromarray(image_np)\n",
    "            draw = ImageDraw.Draw(image_with_boxes)\n",
    "            for box, cls, score in zip(detection_boxes, detection_classes, detection_scores):\n",
    "                if score > detection_threshold:\n",
    "                    y_min, x_min, y_max, x_max = box\n",
    "                    x_min, x_max, y_min, y_max = x_min * image_np.shape[1], x_max * image_np.shape[1], y_min * image_np.shape[0], y_max * image_np.shape[0]\n",
    "                    draw.rectangle([(x_min, y_min), (x_max, y_max)], outline=\"red\", width=2)\n",
    "                    draw.text((x_min, y_min), f'{labels[cls - 1]}: {score:.2f}', fill=\"red\")\n",
    "\n",
    "            # Convert PIL image to base64 encoded string\n",
    "            buffered = io.BytesIO()\n",
    "            image_with_boxes.save(buffered, format=\"JPEG\")\n",
    "            img_str = base64.b64encode(buffered.getvalue())\n",
    "            img_str = img_str.decode('utf-8')\n",
    "\n",
    "            # Clean up saved file\n",
    "            os.remove(file_path)\n",
    "            \n",
    "            # Get the predicted class\n",
    "            highest_score_index = np.argmax(detection_scores)  # Index of the highest score\n",
    "            final_class = labels[detection_classes[highest_score_index] - 1] if detection_scores[highest_score_index] > detection_threshold else \"None\"\n",
    "\n",
    "            # Return the image data for AJAX request\n",
    "            return jsonify({\n",
    "                'image_data': img_str,\n",
    "                'final_class': final_class,\n",
    "                'width': original_width,\n",
    "                'height': original_height\n",
    "            })\n",
    "\n",
    "    return 'No image uploaded or image type not allowed', 400\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b883eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [30/Nov/2023 07:34:28] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [30/Nov/2023 07:34:28] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [30/Nov/2023 07:35:01] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf43c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
